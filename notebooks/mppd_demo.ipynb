{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mppd-title",
   "metadata": {},
   "source": [
    "# Mean Prediction Probability Difference (MPPD) Analysis\n",
    "\n",
    "This notebook focuses specifically on **Mean Prediction Probability Difference (MPPD)** analysis, which measures the difference in predictions between clinically similar patients from different demographic groups.\n",
    "\n",
    "**Key Concepts:**\n",
    "- MPPD measures prediction differences between clinically similar patients from different demographic groups\n",
    "- Higher MPPD values indicate potential bias in the model\n",
    "- Analysis focuses on specific reference groups for cleaner comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-section",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "autoreload",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports-path",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports-src",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import fairness analysis functions\n",
    "from src.util import TestPredictions\n",
    "from src.constants import ATTRIBUTES_REVERSE_MAPPINGS\n",
    "from src.mppd import (\n",
    "    analyze_individual_fairness_by_group,\n",
    "    filter_fairness_results,\n",
    "    plot_multiple_group_comparison_proba_diff,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preparation\n",
    "\n",
    "**To use**: Replace this section with your own data loading code. You need:\n",
    "- `X_test`: DataFrame with features including sensitive attributes\n",
    "- `y_test`: Binary ground truth labels  \n",
    "- `y_pred_proba`: Model probability predictions\n",
    "- `demographic_mappings`: Mappings from codes to group names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEMO DATA LOADING - Replace with your own data loading code\n",
    "# This section shows the expected data structure\n",
    "\n",
    "# Example: Load your trained model predictions\n",
    "# delirium_pred = TestPredictions.load('../output/delirium_xgb_model.pkl')\n",
    "# X_test = delirium_pred.X_test\n",
    "# y_test = delirium_pred.y_test  \n",
    "# y_pred_proba = delirium_pred.y_probs\n",
    "\n",
    "# For demonstration purposes, create sample data structure:\n",
    "print(\"For this demo, you would load your data here.\")\n",
    "print(\"Expected data structure:\")\n",
    "print(\"- X_test: DataFrame with features + sensitive attributes\")\n",
    "print(\"- y_test: Binary labels (0/1)\")\n",
    "print(\"- y_pred_proba: Probability predictions (0-1)\")\n",
    "\n",
    "# Other ways to load data:\n",
    "# UNCOMMENT AND MODIFY FOR YOUR DATA:\n",
    "# X_test = pd.read_csv('your_features.csv')  # Must include demographic columns\n",
    "# y_test = np.load('your_labels.npy')        # Binary outcomes\n",
    "# y_pred_proba = np.load('your_preds.npy')  # Model probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create demographic mappings for your data\n",
    "# MODIFY these mappings to match your data encoding\n",
    "\n",
    "demographic_mappings = {\n",
    "    'race_ethnicity': ATTRIBUTES_REVERSE_MAPPINGS['race_ethnicity'],\n",
    "    'sex': ATTRIBUTES_REVERSE_MAPPINGS['sex'],\n",
    "    'insurance_type': ATTRIBUTES_REVERSE_MAPPINGS['insurance_type']\n",
    "}\n",
    "\n",
    "print(\"Demographic group mappings:\")\n",
    "for attr, mapping in demographic_mappings.items():\n",
    "    print(f\"{attr}: {mapping}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mean Prediction Probability Difference (MPPD) Analysis\n",
    "\n",
    "MPPD measures the difference in predictions between clinically similar patients from different demographic groups.\n",
    "\n",
    "### Key Features:\n",
    "- **Reference Group Analysis**: Uses specific groups as baselines for comparison\n",
    "- **Clinical Similarity**: Only compares patients with similar clinical profiles\n",
    "- **Bias Detection**: Higher MPPD values indicate potential algorithmic bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mppd-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze specific demographic groups for MPPD\n",
    "# UNCOMMENT FOR ACTUAL ANALYSIS:\n",
    "# # Focus on specific reference groups for clearer analysis\n",
    "# race_mppd_df = analyze_individual_fairness_by_group(\n",
    "#     X_test, \n",
    "#     y_pred_proba, \n",
    "#     feature_set='all_clinical',\n",
    "#     distance_threshold=0.01,\n",
    "#     max_samples=10000,\n",
    "#     group_column='race_ethnicity',\n",
    "#     attribute_mappings=ATTRIBUTES_REVERSE_MAPPINGS,\n",
    "#     process_specific_group='White'  # Use White as reference group\n",
    "# )\n",
    "#\n",
    "# sex_mppd_df = analyze_individual_fairness_by_group(\n",
    "#     X_test, \n",
    "#     y_pred_proba,\n",
    "#     feature_set='all_clinical', \n",
    "#     distance_threshold=0.01,\n",
    "#     max_samples=10000,\n",
    "#     group_column='sex',\n",
    "#     attribute_mappings=ATTRIBUTES_REVERSE_MAPPINGS,\n",
    "#     process_specific_group='Female'  # Use Female as reference group\n",
    "# )\n",
    "#\n",
    "# insurance_mppd_df = analyze_individual_fairness_by_group(\n",
    "#     X_test, \n",
    "#     y_pred_proba,\n",
    "#     feature_set='all_clinical',\n",
    "#     distance_threshold=0.01,\n",
    "#     max_samples=10000,\n",
    "#     group_column='insurance_type',\n",
    "#     attribute_mappings=ATTRIBUTES_REVERSE_MAPPINGS,\n",
    "#     process_specific_group='Private'  # Use Private as reference group\n",
    "# )\n",
    "#\n",
    "# # Filter unknown groups\n",
    "# race_mppd_df = filter_fairness_results(race_mppd_df, exclude_groups=['Unknown or declined to state'])\n",
    "# insurance_mppd_df = filter_fairness_results(insurance_mppd_df, exclude_groups=['Unknown'])\n",
    "\n",
    "print(\"MPPD analysis would run here.\")\n",
    "print(\"This focuses on specific reference groups for cleaner comparisons.\")\n",
    "print(\"\")\n",
    "print(\"Reference groups used:\")\n",
    "print(\"- Race/Ethnicity: White as reference\")\n",
    "print(\"- Sex: Female as reference\")\n",
    "print(\"- Insurance: Private as reference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-mppd-viz",
   "metadata": {},
   "source": [
    "## 4. MPPD Visualization\n",
    "\n",
    "Create comprehensive MPPD comparison plots showing prediction differences across all demographic groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-mppd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MPPD comparison plot\n",
    "# UNCOMMENT FOR ACTUAL PLOTTING:\n",
    "# plot_multiple_group_comparison_proba_diff(\n",
    "#     [race_mppd_df, sex_mppd_df, insurance_mppd_df],\n",
    "#     sensitive_attributes=['Race/Ethnicity', 'Sex', 'Insurance Type'],\n",
    "#     title='Mean Prediction Probability Differences of Clinically Similar Patients\\nby Sensitive Attribute Groups',\n",
    "#     figsize=(16, 10),\n",
    "#     save_path=None  # Set to file path to save\n",
    "# )\n",
    "\n",
    "print(\"MPPD comparison plot would appear here.\")\n",
    "print(\"This shows prediction differences between clinically similar patients from different groups.\")\n",
    "print(\"Larger differences indicate potential bias in the model.\")\n",
    "print(\"\")\n",
    "print(\"Plot features:\")\n",
    "print(\"- Violin plots show distribution of prediction differences\")\n",
    "print(\"- Δ (delta) values show the range of differences within each attribute\")\n",
    "print(\"- Reference groups are used as baselines (difference = 0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-mppd-interpretation",
   "metadata": {},
   "source": [
    "## 5. MPPD Results Interpretation\n",
    "\n",
    "### Understanding MPPD Metrics:\n",
    "\n",
    "**MPPD (Mean Prediction Probability Difference):**\n",
    "- Measures prediction differences between clinically similar patients from different demographic groups\n",
    "- **Higher MPPD values indicate potential bias**\n",
    "- The Δ (delta) values show the range of prediction differences within each sensitive attribute\n",
    "\n",
    "### Key Interpretation Guidelines:\n",
    "\n",
    "1. **Reference Group Comparison**: Each group is compared to a reference group (e.g., White, Female, Private insurance)\n",
    "2. **Clinical Similarity**: Only patients with similar clinical profiles (within distance threshold) are compared\n",
    "3. **Bias Detection**: Larger differences suggest the model may be making systematically different predictions for similar patients based on demographic characteristics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
